{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aimW4fVH1VIn"
      },
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "login(\"\") #key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "f19f92f134bc4afbb8311b5c72f5da3b",
            "0f871d84bde34a51ba5c7e3e2bc71edd",
            "33f92984198c4853bab53c9f4c3892e4",
            "479d80d1c6ed497d89d10d9313cdbf30",
            "2f478a77ad5645559b0d7c9218708695",
            "1f7a472191d749d9a7ed49b019a944d4",
            "94942768f3de4661b742e37863c494bf",
            "ac9b739fb74b46618a0e25e73bccbca4",
            "52942c327f4e429a971feea798651d3e",
            "b303459c7b96498cb08116b452887750",
            "984b878e7bbc45f4a71b7987337b8104"
          ]
        },
        "id": "8k-LVxQ3Qm0X",
        "outputId": "53e1e34c-325c-4076-dbd8-a0ca670b34e0"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f19f92f134bc4afbb8311b5c72f5da3b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded on : cuda:0\n"
          ]
        }
      ],
      "source": [
        "!pip install -q transformers accelerate bitsandbytes\n",
        "\n",
        "\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, BitsAndBytesConfig\n",
        "import torch\n",
        "\n",
        "# ======== 1. Loading the 4-bit model ========\n",
        "model_id = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
        "\n",
        "bnb_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16\n",
        ")\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id, trust_remote_code=True)\n",
        "\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    quantization_config=bnb_config,\n",
        "    device_map=\"auto\",\n",
        "    trust_remote_code=True\n",
        ")\n",
        "\n",
        "print(\"Model loaded on :\", model.device)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GuHHb4nLRgZr",
        "outputId": "99e604c3-b91c-499c-f728-0c466b923a92"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Classification des tweets:   0%|          | 0/93 [00:00<?, ?it/s]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:   1%|          | 1/93 [00:04<07:28,  4.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:   2%|▏         | 2/93 [00:09<07:09,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:   3%|▎         | 3/93 [00:15<07:47,  5.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:   4%|▍         | 4/93 [00:19<07:17,  4.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:   5%|▌         | 5/93 [00:24<07:19,  4.99s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:   6%|▋         | 6/93 [00:29<06:59,  4.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:   8%|▊         | 7/93 [00:34<06:51,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:   9%|▊         | 8/93 [00:34<05:01,  3.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  10%|▉         | 9/93 [00:39<05:23,  3.85s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  11%|█         | 10/93 [00:40<04:02,  2.93s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  12%|█▏        | 11/93 [00:52<07:45,  5.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  13%|█▎        | 12/93 [00:53<05:40,  4.21s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  14%|█▍        | 13/93 [00:57<05:43,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  15%|█▌        | 14/93 [01:02<05:59,  4.55s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  16%|█▌        | 15/93 [01:07<05:52,  4.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  17%|█▋        | 16/93 [01:12<06:03,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  18%|█▊        | 17/93 [01:16<05:54,  4.66s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  19%|█▉        | 18/93 [01:21<05:58,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  20%|██        | 19/93 [01:27<06:05,  4.94s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  22%|██▏       | 20/93 [01:31<05:52,  4.83s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  23%|██▎       | 21/93 [01:37<05:56,  4.95s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  24%|██▎       | 22/93 [01:41<05:45,  4.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  25%|██▍       | 23/93 [01:46<05:35,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  26%|██▌       | 24/93 [01:51<05:37,  4.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  27%|██▋       | 25/93 [01:55<05:25,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  28%|██▊       | 26/93 [02:01<05:27,  4.89s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  29%|██▉       | 27/93 [02:05<05:15,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  30%|███       | 28/93 [02:06<03:54,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  31%|███       | 29/93 [02:11<04:15,  4.00s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  32%|███▏      | 30/93 [02:16<04:33,  4.34s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  33%|███▎      | 31/93 [02:21<04:34,  4.43s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  34%|███▍      | 32/93 [02:26<04:43,  4.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  35%|███▌      | 33/93 [02:27<03:31,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  37%|███▋      | 34/93 [02:31<03:45,  3.82s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  38%|███▊      | 35/93 [02:36<04:02,  4.18s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  39%|███▊      | 36/93 [02:37<03:02,  3.20s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  40%|███▉      | 37/93 [02:42<03:22,  3.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  41%|████      | 38/93 [02:46<03:35,  3.92s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  42%|████▏     | 39/93 [02:52<03:50,  4.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  43%|████▎     | 40/93 [02:56<03:51,  4.36s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  44%|████▍     | 41/93 [03:01<03:59,  4.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  45%|████▌     | 42/93 [03:02<02:57,  3.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  46%|████▌     | 43/93 [03:07<03:09,  3.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  47%|████▋     | 44/93 [03:11<03:19,  4.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  48%|████▊     | 45/93 [03:16<03:26,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  49%|████▉     | 46/93 [03:21<03:25,  4.37s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  51%|█████     | 47/93 [03:26<03:31,  4.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  52%|█████▏    | 48/93 [03:30<03:26,  4.59s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  53%|█████▎    | 49/93 [03:35<03:23,  4.62s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  54%|█████▍    | 50/93 [03:40<03:22,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  55%|█████▍    | 51/93 [03:45<03:16,  4.68s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  56%|█████▌    | 52/93 [03:50<03:18,  4.84s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  57%|█████▋    | 53/93 [03:54<03:09,  4.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  58%|█████▊    | 54/93 [03:59<03:02,  4.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  59%|█████▉    | 55/93 [04:04<03:02,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  60%|██████    | 56/93 [04:09<02:55,  4.74s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  61%|██████▏   | 57/93 [04:14<02:54,  4.86s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  62%|██████▏   | 58/93 [04:18<02:47,  4.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  63%|██████▎   | 59/93 [04:23<02:39,  4.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  65%|██████▍   | 60/93 [04:28<02:38,  4.80s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  66%|██████▌   | 61/93 [04:32<02:30,  4.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  67%|██████▋   | 62/93 [04:38<02:31,  4.87s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  68%|██████▊   | 63/93 [04:39<01:50,  3.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  69%|██████▉   | 64/93 [04:43<01:55,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  70%|██████▉   | 65/93 [04:48<01:59,  4.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  71%|███████   | 66/93 [04:53<01:59,  4.41s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  72%|███████▏  | 67/93 [04:58<01:56,  4.48s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  73%|███████▎  | 68/93 [05:03<01:57,  4.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  74%|███████▍  | 69/93 [05:07<01:51,  4.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  75%|███████▌  | 70/93 [05:12<01:47,  4.69s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  76%|███████▋  | 71/93 [05:13<01:19,  3.61s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  77%|███████▋  | 72/93 [05:14<00:58,  2.79s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  78%|███████▊  | 73/93 [05:19<01:06,  3.33s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  80%|███████▉  | 74/93 [05:23<01:10,  3.71s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  81%|████████  | 75/93 [05:28<01:14,  4.13s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  82%|████████▏ | 76/93 [05:33<01:12,  4.26s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  83%|████████▎ | 77/93 [05:38<01:12,  4.56s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  84%|████████▍ | 78/93 [05:43<01:08,  4.58s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  85%|████████▍ | 79/93 [05:47<01:04,  4.57s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  86%|████████▌ | 80/93 [05:52<01:01,  4.70s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  87%|████████▋ | 81/93 [05:57<00:55,  4.65s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  88%|████████▊ | 82/93 [05:58<00:38,  3.52s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  89%|████████▉ | 83/93 [06:03<00:40,  4.01s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  90%|█████████ | 84/93 [06:04<00:27,  3.07s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  91%|█████████▏| 85/93 [06:08<00:28,  3.50s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  92%|█████████▏| 86/93 [06:09<00:19,  2.72s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  94%|█████████▎| 87/93 [06:14<00:20,  3.44s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  95%|█████████▍| 88/93 [06:19<00:18,  3.78s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  96%|█████████▌| 89/93 [06:23<00:15,  3.98s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  97%|█████████▋| 90/93 [06:28<00:12,  4.30s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  98%|█████████▊| 91/93 [06:33<00:08,  4.38s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets:  99%|█████████▉| 92/93 [06:38<00:04,  4.60s/it]Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
            "Classification des tweets: 100%|██████████| 93/93 [06:39<00:00,  4.30s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Results saved in 'classified_tweets.csv'\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ======== 1. Load the tweets ========\n",
        "path = \"/content/cleaned_tweets.json\"\n",
        "with open(path, encoding=\"utf-8\") as f:\n",
        "    tweets_data = json.load(f)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "tweets = [t[\"content_cleaned\"] for t in tweets_data]\n",
        "\n",
        "# ======== 2. List of labels ========\n",
        "labels = [\n",
        "    \"pro pjd\",\n",
        "    \"contre pjd\",\n",
        "    \"pro RNI\",\n",
        "    \"contre RNI\",\n",
        "    \"pro PAM\",\n",
        "    \"contre PAM\",\n",
        "    \"perdre la confiance dans tous les partis politiques\"\n",
        "]\n",
        "\n",
        "# ======== 3. Classification function ========\n",
        "def classify_tweet(text):\n",
        "    prompt = f\"\"\"\n",
        "Here is a list of political labels:\n",
        "{', '.join(labels)}.\n",
        "Read the tweet below, and respond only with one or more of these exact labels (copy-paste).\n",
        "If the tweet contains both support for one party and criticism of another, indicate all relevant labels separated by commas.\n",
        "Do not provide any explanation. Do not rephrase. Do not respond with anything else.\n",
        "\n",
        "If the tweet mentions only the word \"حكومة\" (government) **without specifying a name or date**, assume it refers to the **current government (RNI)**.\n",
        "\n",
        "**Important instructions**:\n",
        "- If the tweet expresses **explicit or implicit support** for a party, choose a \"pro\" type label.\n",
        "- If the tweet expresses **criticism, rejection, or dissatisfaction** towards a party, choose a \"critique\" or \"contre\" type label.\n",
        "- If the tweet criticizes one party **and** supports another, indicate **both labels** separated by commas.\n",
        "- If a tweet speaks positively about Morocco's current achievements without mentioning a party, assume it indirectly supports the current government (RNI).\n",
        "- If a tweet compares PJD's reforms as necessary and criticizes the current government’s as harmful, classify it as **Pro PJD and Anti RNI**.\n",
        "- If a tweet criticizes \"the current government\" without mentioning a party, consider it targets the RNI.\n",
        "- If a tweet only talks about social problems without naming a responsible party, choose \"contre RNI\".\n",
        "- Do not create any new labels. Do not mix different phrasings. Keep exactly the form of the proposed labels.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "Tweet : {text}\n",
        "Étiquette :\"\"\"\n",
        "\n",
        "    inputs = tokenizer(prompt, return_tensors=\"pt\").to(model.device)\n",
        "    outputs = model.generate(**inputs, max_new_tokens=50)\n",
        "    result = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
        "\n",
        "    # Strict extraction after \"Label\" :\"\n",
        "    if \"Étiquette :\" in result:\n",
        "        return result.split(\"Étiquette :\")[1].strip().split(\"\\n\")[0]\n",
        "    return result.strip().split(\"\\n\")[0]\n",
        "\n",
        "\n",
        "# ======== 4. Apply the classification to all tweets ========\n",
        "results = []\n",
        "for t in tqdm(tweets, desc=\"Classification des tweets\"):\n",
        "    label = classify_tweet(t)\n",
        "    results.append(label)\n",
        "\n",
        "# ======== 5. Save the results ========\n",
        "df = pd.DataFrame({\n",
        "    \"tweet\": tweets,\n",
        "    \"classe\": results\n",
        "})\n",
        "\n",
        "df.to_csv(\"classified_tweets.csv\", index=False, encoding=\"utf-8-sig\")\n",
        "print(\"✅ Results saved in 'classified_tweets.csv'\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0f871d84bde34a51ba5c7e3e2bc71edd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1f7a472191d749d9a7ed49b019a944d4",
            "placeholder": "​",
            "style": "IPY_MODEL_94942768f3de4661b742e37863c494bf",
            "value": "Loading checkpoint shards: 100%"
          }
        },
        "1f7a472191d749d9a7ed49b019a944d4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2f478a77ad5645559b0d7c9218708695": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "33f92984198c4853bab53c9f4c3892e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac9b739fb74b46618a0e25e73bccbca4",
            "max": 3,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_52942c327f4e429a971feea798651d3e",
            "value": 3
          }
        },
        "479d80d1c6ed497d89d10d9313cdbf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b303459c7b96498cb08116b452887750",
            "placeholder": "​",
            "style": "IPY_MODEL_984b878e7bbc45f4a71b7987337b8104",
            "value": " 3/3 [01:41&lt;00:00, 33.55s/it]"
          }
        },
        "52942c327f4e429a971feea798651d3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "94942768f3de4661b742e37863c494bf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "984b878e7bbc45f4a71b7987337b8104": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac9b739fb74b46618a0e25e73bccbca4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b303459c7b96498cb08116b452887750": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f19f92f134bc4afbb8311b5c72f5da3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f871d84bde34a51ba5c7e3e2bc71edd",
              "IPY_MODEL_33f92984198c4853bab53c9f4c3892e4",
              "IPY_MODEL_479d80d1c6ed497d89d10d9313cdbf30"
            ],
            "layout": "IPY_MODEL_2f478a77ad5645559b0d7c9218708695"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
