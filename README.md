# ğŸŸ¢ Moroccan-Political-Insight

**Moroccan-Political-Insight** is a comprehensive project designed to analyze and visualize political opinions and trends in Morocco. It implements a **real-time Big Data pipeline**, leverages a **large language model (Mistral 7B)** for tweet classification, and performs **parallel sentiment analysis in Java**. Finally, the results are presented in an interactive **Streamlit dashboard**.  

---

## ğŸ“Œ Project Overview

This project provides insights into Moroccan political discussions on social media by analyzing public tweets related to political parties, leaders, and government actions. The pipeline includes:

1. **Data ingestion**: Tweets are collected and stored in Firebase.  
2. **Real-time streaming & cleaning**: Data is streamed from Firebase to Kafka, processed with Spark Streaming, and stored in Hadoop HDFS.  
3. **Export cleaned data**: Cleaned JSON tweets are exported from Hadoop to local storage using WinSCP.  
4. **AI-based classification**: Tweets are classified using the **Mistral 7B** model to detect support or criticism toward political parties.  
5. **Parallel sentiment analysis (Java)**: Positive, negative, and neutral tweet counts are computed, with top keywords identified using a parallelized Java implementation.  
6. **Interactive dashboard**: A Streamlit app visualizes trends, keyword frequencies, and classification results.  


---

## ğŸ—‚ï¸ Project Structure
```
Moroccan-Political-Insight/
â”‚â”€â”€ README.md
â”‚â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ producer/                     # Data ingestion
â”‚   â””â”€â”€ firebase_producer.py
â”‚
â”œâ”€â”€ streaming/                    # Real-time cleaning
â”‚   â””â”€â”€ stream_to_hdfs.py
â”‚
â”œâ”€â”€ data/                         # Raw input data
â”‚   â””â”€â”€ tweets.json
â”‚
â”œâ”€â”€ exports/                      # Data exported from Hadoop
â”‚   â””â”€â”€ cleaned_tweets.json
â”‚
â”œâ”€â”€ LLM_classification/               # AI classification (Colab)
â”‚   â””â”€â”€ mistral_classification.ipynb
â”‚
â”œâ”€â”€ parallel_analysis/             # Java sentiment analysis
â”‚   â”œâ”€â”€ Tweet.java
â”‚   â”œâ”€â”€ AnalysisResult.java
â”‚   â”œâ”€â”€ TweetAnalyzer.java
â”‚   â””â”€â”€ Main.java
â”‚
â”œâ”€â”€ dashboard/                    # Visualization
â”‚   â””â”€â”€ app.py
â”‚
â””â”€â”€ commands/                     # Hadoop, Kafka & Spark commands
    â””â”€â”€ hadoop_commands.txt

```

---

## ğŸ› ï¸ Key Components

### 1ï¸âƒ£ Producer: `firebase_producer.py`
- Reads raw tweets from Firebase Realtime Database.  
- Publishes tweets to a Kafka topic (`json-topic`) for real-time streaming.

### 2ï¸âƒ£ Streaming: `stream_to_hdfs.py`
- Spark Structured Streaming job that:
  - Reads tweets from Kafka.  
  - Cleans the text (removes extra spaces, special characters).  
  - Saves the cleaned data to **HDFS** in JSON format.  

### 3ï¸âƒ£ Exports
- `cleaned_tweets.json` is first exported from HDFS to the local Hadoop VM using Hadoop commands:
 ``` hdfs dfs -get /user/root/cleaned_tweets_output_json/part-00000-*.json /root/cleaned_tweets.json```
- Then, the file is copied from the Hadoop VM to Windows using WinSCP.
- This ensures the cleaned dataset is available locally for LLM classification.
 
### 4ï¸âƒ£ Classification: `mistral_classification.ipynb`
- Loads **cleaned tweets**.  
- Uses **Mistral 7B LLM** for classification into political labels (pro/contre parties).  
- Generates a CSV with `tweet` and `classe` columns.

### 5ï¸âƒ£ Parallel Analysis: Java
- Computes **positive, negative, and neutral tweet counts** in parallel.  
- Extracts top keywords for positive and negative tweets.  
- Classes: `Tweet`, `TweetAnalyzer`, `AnalysisResult`, and `Main`.

### 6ï¸âƒ£ Dashboard: `dashboard_app.py`
- Streamlit-based interactive dashboard.  
- Visualizes:
  - Tweet distribution by political class.  
  - Top keywords in positive/negative tweets.  
  - Interactive trend graphs.

### 7ï¸âƒ£ Commands: `hadoop_commands.txt`
- Provides **step-by-step commands** for:
  - Starting Zookeeper and Kafka.  
  - Creating Kafka topics.  
  - Running Spark Streaming.  
  - Exporting cleaned tweets from HDFS.

---

## âš¡ Workflow / Pipeline
```
Firebase (raw tweets)
      â”‚
      â–¼
Kafka Topic ("json-topic")
      â”‚
      â–¼
Spark Streaming â†’ HDFS (cleaned_tweets.json)
      â”‚
      â–¼
Export from HDFS â†’ Local Hadoop VM â†’ Windows (WinSCP)
      â”‚
      â–¼
LLM Classification (Mistral 7B, in Colab)
      â”‚
      â–¼
Parallel Sentiment Analysis (Java)
      â”‚
      â–¼
Streamlit Dashboard (dashboard_app.py)
```
---
## ğŸ› ï¸ Tech Stack

- **Data sources & ingestion**: Firebase Realtime Database

- **Streaming & Processing**: Kafka, Apache Spark Streaming, Hadoop HDFS

- **LLM Classification**: Mistral 7B (executed in Google Colab)

- **Parallel Analysis**: Java (multithreaded sentiment analysis)

- **Visualization**: Streamlit

- **Utilities** : WinSCP (for file transfer from Hadoop VM to Windows)
##  ğŸ‘©â€ğŸ’» Author

**Meriam Sikini**
